= 3장. 의사결정 트리
마치 스무고개처럼 동작, 분류 기술 중 가장 일반적인 영역
의사결정 영역, 단말 영역

== 3.1 트리구조
* 장점
** 계산 비용 적음
** 학습결과를 사람이 이해 쉬움,
** 누락된 값이 있어도 처리 가능. 분류와 상관없는 속성이 있어도 처리
* 단점
** overfitting 되기 쉬움
* 적용 : 수치형값, 명목형 값
* 정보 이론
** ID3 알고리즘: 정보이득이 높은 방향으로 트리를 나눠서 하위를 구성
*** 범주형에만 사용, 상위노드에 사용된 속성은 사용 안함
image:../../images/ch3.decision-tree/entropy.png[]
*** 정보이득 (information gain) : 데이터 분할 전과 후의 변화
*** 엔트로피 (entropy) : 높을 수록 그만 큼 더 혼잡함
** 그외 알고리즘 : ID3, C4.5, CART 등

== 3.2 code 설명
* 핵심: ID3 를 사용하므로, 정보이득이 많은 feature를 선택하여 데이터를 나누면서 leaf를 만들어 나감

== 3.3 분류기 검사와 저장
* classify 로 내가 가진 데이터로 값 유추

== 3.4 예제: 콘택트렌즈 유형 예측하기
* 과적합 (overfitting)
** 말 그대로 과도하게 모델을 leaning 함. 따라서 현실 세계에선 해결 못함
** 과적합 문제를 줄이려면 가지치기 (prune) 을 해야함
** 해결방법: 1.features의 수를 줄이는 방법, 2.정규화(regularzation) : 모든 feature 쓰되, 값과 크기를 줄임

* underfitting
** 다 똑같은 결론을 만들 수 있는 문제

== 3.5 요약
* 데이터의 집합 분할을 위해 엔트로피를 측정
