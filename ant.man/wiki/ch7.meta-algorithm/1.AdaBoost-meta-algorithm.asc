= 7장 에이다부스트 메타 알고리즘으로 분류 개선하기
* 앙상블 (ensemble): 여러개의 정확하지 않은 알고리즘을 이용해 최적의 답을 찾아내는 기법
* meta algorithm (= ensemble method): 서로 다른 알고리즘들을 병합하는 방법 중 하나

* Bagging : 학습셋에서 랜덤하게 서브셋을 추출해(boostrap resampling) 이를 기반으로 모형을 만드는데 이런 과정을 N번만큼 반복해 복수개의 모형을 만들어 이들의 voting으로 예측을 하는 모형
* Boosting : 예측 성능이 조금 낮은 분류기(weak)를 조합해 좀 더 좋은 성능을 발휘하는 강한 분류기 만드는 방법
* Adaboost : 약 분류기 (weak classifier) 들이 상호 보완 하도록 단계적(순차적) 학습하여 최종적을 강 분류기의 성능을 증폭
** 학습 시 이전 분류기의 오분류 샘플의 가중치를 adaptive 하게 바꿔 잘못 분류된 데이터에 더 집중

* 분류 불균형에 대해 이야기 할 예정

== 7.1 데이터 집합의 다양한 표본을 사용하는 분류기
* ensemble method: 서로 다른 알고리즘을 사용하거나, 하나의 알고리즘에 설정을 다르게하거나 데이터 집합의 서로다른 부분을 서로 다른 분류기에 적용하여 처리
* Bagging: 다양한 분류기 통합하는 방법
** S개의 분류기를 새로운 데이터에 적용하고 다수결로 결정
** 랜덤 포레스트 등
* Boosting : Bagging과 유사하지만, 배깅은 언제나 동일한 유형의 분류기를 사용, Boosting은 순차적으로 다른 유형의 분류기 사용 (이전 분류기에서 잘못된 것에 초점)
** Adaboost 등

== 7.2 훈련: 오류에 초점을 맞춘 분류기 개선
* 가중치는 훈련데이터 모두에 적용 (초기에는 가중치가 모두 동일)
* 첫 훈련 데이터로 오류 계산 후 분류된 예제들은 가중치를 낮게 부여하고, 확실히 분류 안된건 더 높은 가중치를 부여
* 각 분류기에 알파 값을 부여하고, 확실히 예측할 경우와 예측 못할경우에 따라 가중치를 구하여 각각 적용
image:../../images/ch7.meta-algorithm/Adaboost0.jpg[]

** 막대기는 각각 사례에 적용된 가중치, 삼각형은 알파값에 다른 분류기의 가중치

image:../../images/ch7.meta-algorithm/Adaboost1.png[]
image:../../images/ch7.meta-algorithm/Adaboost2.png[]

ref1 : https://m.blog.naver.com/dic1224/220669575477
ref2 : https://dic1224.blog.me/220989033563

== 7.3 의사결정 스텀프로 약한 학습기 생성하기
stumpClassify() :
buildStamp() :

== 7.4 전체 에이다부스트 알고리즘 구현하기
adaBoostTrainDS() :

== 7.5 검사: 에이타부스트로 분류하기
addClassify() : 이미 계산된 (학습된) alpha 값으로 새로운 값에 대한 결과 값 도출

== 7.6 예제: 에이타부스트에 복잡한 데이터 집합 적용하기
배앓이 데이터로 다시 학습 및 평가

== 7.7 분류 불균형
* 분류에 대한 대상에 대한 비용이 동일
** 분류 후 어떤 일이 발생 -> 원하고자 하는 목표에 따라 측정 목표가 다름
* 책에서 계속본 오류율: 분류를 제대로 못한 사례 / 전체 사례
image:../../images/ch7.meta-algorithm/pn_matrix.png[]
** precision = tp / tp+fp
** recall (sensitivity) = tp / tp+fn
** specificity (True negative rate) = tn / tn+ fp
** accuracy = tp+tn / tp+tn+fp+fn
* https://ko.wikipedia.org/wiki/%EC%A0%95%EB%B0%80%EB%8F%84%EC%99%80_%EC%9E%AC%ED%98%84%EC%9C%A8[정밀도와 재현율]

* ROC 곡선 (ROC Curve)
image:../../images/ch7.meta-algorithm/ROC-Curve.png[]

** TPR (True Positive Rate, 민감도): 1인 케이스틑 1로 예측한 비율 (암환자를 진찰해 암으로 진단함)
** FPR (False Positive Rate =1-특이도): 0인 케이스를 1로 잘못 예측한 비율 (암환자가 아닌데 암으로 진단함)
** AUC = AUROC (the Area Under a ROC Curve) : ROC 커브의 밑면적을 구한 값이 바로 AUC. 이 값이 1에 가까울수록 성능이 좋다.


== 7.8 요약
* 앙상블 매소드
** Bagging
** Boosting

* 랜덤포레스트
* 에이다부스트
