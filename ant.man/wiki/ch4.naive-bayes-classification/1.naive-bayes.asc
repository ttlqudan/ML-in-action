= 4장. 나이브 베이스: 확률 이론으로 분류하기
* naive? 순진한 고지식한

<기본 이론 정리>

* http://www.aistudy.com/math/conditional_probability.htm[조건부확률 예제]
* https://zetawiki.com/wiki/%EB%8F%85%EB%A6%BD%EC%82%AC%EA%B1%B4,_%EC%A2%85%EC%86%8D%EC%82%AC%EA%B1%B4,_%EB%B0%B0%EB%B0%98%EC%82%AC%EA%B1%B4[독립,조건,배반 사건]
** 독립: 서로 다른 사건이 일어날 확률에 영향 주지 않는 사건들 image:../../images/ch4.naive-bayes/독립사건.png[]
** 종속: 사건 A 가 일어났을 경우와 안일어 났을 경우에 따라 사건 B가 일어날 확률이 다를때, B는 A 에 종속사건 image:../../images/ch4.naive-bayes/종속사건.png[]
** 배반: 동시에 일어날 수 없는 두 사건 image:../../images/ch4.naive-bayes/배반사건.png[]
*  https://ko.wikipedia.org/wiki/%EB%82%98%EC%9D%B4%EB%B8%8C_%EB%B2%A0%EC%9D%B4%EC%A6%88_%EB%B6%84%EB%A5%98[나이브베이즈분류-wiki]

* 나이브 베이즈 분류를 구현시 발생하는 문제점을 해결하기 위하여 라플라스 스무딩과 로그확률을 사용
* http://untitledtblog.tistory.com/31 [머신러닝-라플라스스무딩과 로그확률에 대하여]
** 라플라스 스무딩(Laplace smoothing)
** 로그확률(Log-probability)
*** 확률은 1보다 작거나 같음. 많은 확률을 곱하면 0으로 수렴됨 -> 높은 차원데이터 해결하기 위한 방법으로 log 를 적용함
image:../../images/ch4.naive-bayes/log-probability.png[]

== 4.1 베이지안 의사결정 이론으로 분류
* 장점: 소량의 데이터로 작업 이뤄지며 여러개 분류 항목 다룰 수 있음
* 단점: 입력 데이터를 어떻게 준비하느냐에 따라 민감하게 작용

== 4.2 조건부 확률

== 4.3 조건부 확률로 분류하기

== 4.4 나이브 베이스로 문서 분류하기

== 4.5 파이썬으로 텍스트 분류하기

== 4.6 예제: 스팸 이메일 분류하기

== 4.7 예제: 개인 광고에 포함된 지역 특색 도출하기
